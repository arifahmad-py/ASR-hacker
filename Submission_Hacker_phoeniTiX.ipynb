{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Submission_Hacker_phoeniTiX.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6225e794ccd747be8931ff4f3e529e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9a6e958cb7d48b5bab0c424b9303cad",
              "IPY_MODEL_c77b89834281495b981b7c1f84a21c9c",
              "IPY_MODEL_570d12e320ea4cc09614b4559a729546"
            ],
            "layout": "IPY_MODEL_b80450ed2e3b44d9bc4c2101b599c9d3"
          }
        },
        "f9a6e958cb7d48b5bab0c424b9303cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de3a9c30675c485db1b17f4e13a0ff8c",
            "placeholder": "​",
            "style": "IPY_MODEL_2c1fdc7e7ecf4b4eab9f7864c5360728",
            "value": "Downloading: 100%"
          }
        },
        "c77b89834281495b981b7c1f84a21c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08d06fb006724ca6a46d9d2c498b6e21",
            "max": 1768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9e59e63391d48af9431218ad8c01d2e",
            "value": 1768
          }
        },
        "570d12e320ea4cc09614b4559a729546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1b55633b3b3439b995c71a4f0d81afb",
            "placeholder": "​",
            "style": "IPY_MODEL_888fb87f83964bbdad45ca5c03eadd1a",
            "value": " 1.73k/1.73k [00:00&lt;00:00, 77.7kB/s]"
          }
        },
        "b80450ed2e3b44d9bc4c2101b599c9d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de3a9c30675c485db1b17f4e13a0ff8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c1fdc7e7ecf4b4eab9f7864c5360728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08d06fb006724ca6a46d9d2c498b6e21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9e59e63391d48af9431218ad8c01d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1b55633b3b3439b995c71a4f0d81afb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "888fb87f83964bbdad45ca5c03eadd1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d68dd4095d684caf895d1b4e6c9c546f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a55b51510444565973a02dbfa4fbba5",
              "IPY_MODEL_b0eb853c72c9413f9f3c2bffad7313a9",
              "IPY_MODEL_09e101ce05ed4f058b5c5f268b9ee9e4"
            ],
            "layout": "IPY_MODEL_250cfab4eaa54f13bb8626421da63106"
          }
        },
        "3a55b51510444565973a02dbfa4fbba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96675e35707f4b5092374250193971e2",
            "placeholder": "​",
            "style": "IPY_MODEL_772d34fe149e460bbe938c244091589c",
            "value": "Downloading: 100%"
          }
        },
        "b0eb853c72c9413f9f3c2bffad7313a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_574689e2ca1a4be8b07d4ccf46d44ecf",
            "max": 1269737156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02da289ab8d3450091fac60376e2b431",
            "value": 1269737156
          }
        },
        "09e101ce05ed4f058b5c5f268b9ee9e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_653df1e0cab249468c10018829bb37b6",
            "placeholder": "​",
            "style": "IPY_MODEL_4c8d9bab9e67473f946d95c219618011",
            "value": " 1.18G/1.18G [00:18&lt;00:00, 68.7MB/s]"
          }
        },
        "250cfab4eaa54f13bb8626421da63106": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96675e35707f4b5092374250193971e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "772d34fe149e460bbe938c244091589c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "574689e2ca1a4be8b07d4ccf46d44ecf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02da289ab8d3450091fac60376e2b431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "653df1e0cab249468c10018829bb37b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c8d9bab9e67473f946d95c219618011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Requirements"
      ],
      "metadata": {
        "id": "5yyoe3_vl3_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('requirements.txt', 'w') as f:\n",
        "    f.write('torch\\ntorchvision\\ntorchaudio\\npraat-parselmouth\\ntransformers\\nomegaconf\\npytorch_lightning\\ntqdm\\ntensorboard\\nlibrosa >= 0.8.0')"
      ],
      "metadata": {
        "id": "ADI0FfJ6l56E"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Sy1_sFEbl-Uw",
        "outputId": "1d5e983a-6289-47c1-d418-90b66455032f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.12.0+cu113)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.11.0+cu113)\n",
            "Collecting praat-parselmouth\n",
            "  Downloading praat_parselmouth-0.4.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (10.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.7 MB 8.2 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 72.3 MB/s \n",
            "\u001b[?25hCollecting omegaconf\n",
            "  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.6.3-py3-none-any.whl (584 kB)\n",
            "\u001b[K     |████████████████████████████████| 584 kB 88.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (4.64.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.8.0)\n",
            "Requirement already satisfied: librosa>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (0.8.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->-r requirements.txt (line 10)) (2.1.9)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->-r requirements.txt (line 10)) (4.4.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->-r requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->-r requirements.txt (line 10)) (21.3)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->-r requirements.txt (line 10)) (1.6.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->-r requirements.txt (line 10)) (1.1.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->-r requirements.txt (line 10)) (0.2.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->-r requirements.txt (line 10)) (0.10.3.post1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->-r requirements.txt (line 10)) (1.21.6)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->-r requirements.txt (line 10)) (0.51.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->-r requirements.txt (line 10)) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.8.0->-r requirements.txt (line 10)) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.8.0->-r requirements.txt (line 10)) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa>=0.8.0->-r requirements.txt (line 10)) (3.0.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.8.0->-r requirements.txt (line 10)) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.8.0->-r requirements.txt (line 10)) (1.4.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->-r requirements.txt (line 10)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->-r requirements.txt (line 10)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->-r requirements.txt (line 10)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->-r requirements.txt (line 10)) (3.0.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa>=0.8.0->-r requirements.txt (line 10)) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.8.0->-r requirements.txt (line 10)) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa>=0.8.0->-r requirements.txt (line 10)) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.8.0->-r requirements.txt (line 10)) (2.21)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 2)) (7.1.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 77.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 5)) (4.11.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 75.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 5)) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 79.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 5)) (3.6.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 78.2 MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n",
            "\u001b[K     |████████████████████████████████| 409 kB 75.9 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 76.1 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate<0.4.0,>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 9)) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 9)) (0.37.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 9)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 9)) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.44.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 9)) (3.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 9)) (1.0.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 72.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 9)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 9)) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 9)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 9)) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers->-r requirements.txt (line 5)) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 9)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 9)) (3.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 90.7 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 80.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 7)) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning->-r requirements.txt (line 7)) (2.0.12)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->-r requirements.txt (line 5)) (7.1.2)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, sacremoses\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=89958889a0e3e58d2228f77eddb541c54b6a8df8f294d66d927b443da386db54\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=365432d2a668af3b86fefe315588ff462dd9bb42812e6970c5d1405271a3409b\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built antlr4-python3-runtime sacremoses\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyyaml, pyDeprecate, fsspec, aiohttp, torchmetrics, tokenizers, sacremoses, huggingface-hub, antlr4-python3-runtime, transformers, pytorch-lightning, praat-parselmouth, omegaconf\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 antlr4-python3-runtime-4.8 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.3.0 huggingface-hub-0.5.1 multidict-6.0.2 omegaconf-2.1.2 praat-parselmouth-0.4.1 pyDeprecate-0.3.2 pytorch-lightning-1.6.3 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 torchmetrics-0.8.2 transformers-4.18.0 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utils"
      ],
      "metadata": {
        "id": "6Kpdq-Ngqf8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/arifahmad-py/ASR-hacker.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K52TiDYRqg_0",
        "outputId": "063a5a4a-3c69-4477-952d-e1e54580bab9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ASR-hacker'...\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 32 (delta 10), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (32/32), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/ASR-hacker/utils /content"
      ],
      "metadata": {
        "id": "LbXwIZtBqkF_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#yingram calculation model"
      ],
      "metadata": {
        "id": "HKcolXNRj9FS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adapted from https://github.com/patriceguyot/Yin\n",
        "# https://github.com/NVIDIA/mellotron/blob/master/yin.py\n",
        "\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "WDUvBG01j_NO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def differenceFunction(x, N, tau_max):\n",
        "    \"\"\"\n",
        "    Compute difference function of data x. This corresponds to equation (6) in [1]\n",
        "    This solution is implemented directly with Numpy fft.\n",
        "    :param x: audio data\n",
        "    :param N: length of data\n",
        "    :param tau_max: integration window size\n",
        "    :return: difference function\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "\n",
        "    x = np.array(x, np.float64)\n",
        "    w = x.size\n",
        "    tau_max = min(tau_max, w)\n",
        "    x_cumsum = np.concatenate((np.array([0.]), (x * x).cumsum()))\n",
        "    size = w + tau_max\n",
        "    p2 = (size // 32).bit_length()\n",
        "    nice_numbers = (16, 18, 20, 24, 25, 27, 30, 32)\n",
        "    size_pad = min(x * 2 ** p2 for x in nice_numbers if x * 2 ** p2 >= size)\n",
        "    fc = np.fft.rfft(x, size_pad)\n",
        "    conv = np.fft.irfft(fc * fc.conjugate())[:tau_max]\n",
        "    return x_cumsum[w:w - tau_max:-1] + x_cumsum[w] - x_cumsum[:tau_max] - 2 * conv\n"
      ],
      "metadata": {
        "id": "Et2pHyFmkBYD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cumulativeMeanNormalizedDifferenceFunction(df, N, eps=1e-8):\n",
        "    \"\"\"\n",
        "    Compute cumulative mean normalized difference function (CMND).\n",
        "    This corresponds to equation (8) in [1]\n",
        "    :param df: Difference function\n",
        "    :param N: length of data\n",
        "    :return: cumulative mean normalized difference function\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    np.seterr(divide='ignore', invalid='ignore')\n",
        "    # scipy method, assert df>0 for all element\n",
        "    cmndf = df[1:] * np.asarray(list(range(1, N))) / (np.cumsum(df[1:]).astype(float) + eps)\n",
        "    return np.insert(cmndf, 0, 1)\n"
      ],
      "metadata": {
        "id": "VdSHLeewkDTE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def differenceFunctionBatch(xs: np.ndarray, N, tau_max):\n",
        "    \"\"\"numpy backend batch-wise differenceFunction\n",
        "    Args:\n",
        "        xs: audio segments, np.ndarray of shape (B x t)\n",
        "        N:\n",
        "        tau_max:\n",
        "    Returns:\n",
        "        y: dF. np.ndarray of shape (B x tau_max)\n",
        "    \"\"\"\n",
        "    xs = xs.astype(np.float64)\n",
        "    w = xs.shape[-1]\n",
        "    tau_max = min(tau_max, w)\n",
        "    zeros = np.zeros((xs.shape[0], 1))\n",
        "    x_cumsum = np.concatenate((np.zeros((xs.shape[0], 1)), (xs * xs).cumsum(axis=-1)), axis=-1)  # B x w\n",
        "    size = w + tau_max\n",
        "    p2 = (size // 32).bit_length()\n",
        "    nice_numbers = (16, 18, 20, 24, 25, 27, 30, 32)\n",
        "    size_pad = min(x * 2 ** p2 for x in nice_numbers if x * 2 ** p2 >= size)\n",
        "\n",
        "    convs = []\n",
        "    for i in range(xs.shape[0]):\n",
        "        x = xs[i]\n",
        "        fc = np.fft.rfft(x, size_pad)\n",
        "        conv = np.fft.irfft(fc * fc.conjugate())[:tau_max]\n",
        "        convs.append(conv)\n",
        "    convs = np.asarray(convs)\n",
        "\n",
        "    y = x_cumsum[:, w:w - tau_max:-1] + x_cumsum[:, w, np.newaxis] - x_cumsum[:, :tau_max] - 2 * convs\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "EusEbMi7kFcX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cumulativeMeanNormalizedDifferenceFunctionBatch(dFs, N, eps=1e-8):\n",
        "    \"\"\"numpy backend batch-wise cumulative Mean Normalized Difference Functions\n",
        "    Args:\n",
        "        dFs: differenceFunctions. np.ndarray of shape (B x tau_max)\n",
        "        N:\n",
        "        eps:\n",
        "    Returns:\n",
        "        cMNDFs: np.ndarray of shape (B x tau_max)\n",
        "    \"\"\"\n",
        "    arange = np.asarray(list(range(1, N)))[np.newaxis, ...]\n",
        "    cumsum = np.cumsum(dFs[:, 1:], axis=-1).astype(float)\n",
        "    cMNDFs = dFs[:, 1:] * arange / (cumsum + eps)\n",
        "    cMNDFs = np.concatenate((np.zeros((cMNDFs.shape[0], 1)), cMNDFs), axis=1)\n",
        "    return cMNDFs\n"
      ],
      "metadata": {
        "id": "2F5JHGCckH5v"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def differenceFunctionTorch(xs: torch.Tensor, N, tau_max) -> torch.Tensor:\n",
        "    \"\"\"pytorch backend batch-wise differenceFunction\n",
        "    has 1e-4 level error with input shape of (32, 22050*1.5)\n",
        "    Args:\n",
        "        xs:\n",
        "        N:\n",
        "        tau_max:\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    xs = xs.double()\n",
        "    w = xs.shape[-1]\n",
        "    tau_max = min(tau_max, w)\n",
        "    zeros = torch.zeros((xs.shape[0], 1))\n",
        "    x_cumsum = torch.cat(\n",
        "        (torch.zeros((xs.shape[0], 1), device=xs.device), (xs * xs).cumsum(dim=-1, dtype=torch.double)),\n",
        "        dim=-1)  # B x w\n",
        "    size = w + tau_max\n",
        "    p2 = (size // 32).bit_length()\n",
        "    nice_numbers = (16, 18, 20, 24, 25, 27, 30, 32)\n",
        "    size_pad = min(x * 2 ** p2 for x in nice_numbers if x * 2 ** p2 >= size)\n",
        "\n",
        "    fcs = torch.fft.rfft(xs, n=size_pad, dim=-1)\n",
        "    convs = torch.fft.irfft(fcs * fcs.conj())[:, :tau_max]\n",
        "    y1 = torch.flip(x_cumsum[:, w - tau_max + 1:w + 1], dims=[-1])\n",
        "    y = y1 + x_cumsum[:, w, np.newaxis] - x_cumsum[:, :tau_max] - 2 * convs\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "CnSm9lblkKXk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cumulativeMeanNormalizedDifferenceFunctionTorch(dfs: torch.Tensor, N, eps=1e-8) -> torch.Tensor:\n",
        "    arange = torch.arange(1, N, device=dfs.device, dtype=torch.float64)\n",
        "    cumsum = torch.cumsum(dfs[:, 1:], dim=-1, dtype=torch.float64).to(dfs.device)\n",
        "\n",
        "    cmndfs = dfs[:, 1:] * arange / (cumsum + eps)\n",
        "    cmndfs = torch.cat(\n",
        "        (torch.ones(cmndfs.shape[0], 1, device=dfs.device), cmndfs),\n",
        "        dim=-1)\n",
        "    return cmndfs"
      ],
      "metadata": {
        "id": "0N2cl7nRkMfD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wav = torch.randn(32, int(22050 * 1.5)).cuda()\n",
        "wav_numpy = wav.detach().cpu().numpy()\n",
        "x = wav_numpy[0]\n",
        "\n",
        "w_len = 2048\n",
        "w_step = 256\n",
        "tau_max = 2048\n",
        "W = 2048\n",
        "\n",
        "startFrames = list(range(0, x.shape[-1] - w_len, w_step))\n",
        "startFrames = np.asarray(startFrames)\n",
        "# times = startFrames / sr\n",
        "frames = [x[..., t:t + W] for t in startFrames]\n",
        "frames = np.asarray(frames)\n",
        "frames_torch = torch.from_numpy(frames).cuda()\n",
        "\n",
        "cmndfs0 = []\n",
        "for idx, frame in enumerate(frames):\n",
        "    df = differenceFunction(frame, frame.shape[-1], tau_max)\n",
        "    cmndf = cumulativeMeanNormalizedDifferenceFunction(df, tau_max)\n",
        "    cmndfs0.append(cmndf)\n",
        "cmndfs0 = np.asarray(cmndfs0)\n",
        "\n",
        "dfs = differenceFunctionTorch(frames_torch, frames_torch.shape[-1], tau_max)\n",
        "cmndfs1 = cumulativeMeanNormalizedDifferenceFunctionTorch(dfs, tau_max).detach().cpu().numpy()\n",
        "print(cmndfs0.shape, cmndfs1.shape)\n",
        "print(np.sum(np.abs(cmndfs0 - cmndfs1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW29XpIukPFB",
        "outputId": "86486e13-8060-45e6-b3a0-4866eec760e8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(122, 2048) (122, 2048)\n",
            "1.269745013829122e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ecpa models"
      ],
      "metadata": {
        "id": "v9iTius4kVnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "OGM2s2OylCa3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv1D_ReLU_BN(nn.Module):\n",
        "    def __init__(self, c_in, c_out, ks, stride, padding, dilation):\n",
        "        super(Conv1D_ReLU_BN, self).__init__()\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv1d(c_in, c_out, ks, stride, padding, dilation),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(c_out),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.network(x)\n",
        "        return y"
      ],
      "metadata": {
        "id": "_Yc5qlnBlEVl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Res2_Conv1D(nn.Module):\n",
        "    def __init__(self, c, scale, ks, stride, padding, dilation):\n",
        "        super(Res2_Conv1D, self).__init__()\n",
        "        assert c % scale == 0\n",
        "        self.c = c\n",
        "        self.scale = scale\n",
        "        self.width = c // scale\n",
        "\n",
        "        self.convs = []\n",
        "        self.bns = []\n",
        "\n",
        "        for i in range(scale - 1):\n",
        "            self.convs.append(nn.Conv1d(self.width, self.width, ks, stride, padding, dilation))\n",
        "            self.bns.append(nn.BatchNorm1d(self.width))\n",
        "        self.convs = nn.ModuleList(self.convs)\n",
        "        self.bns = nn.ModuleList(self.bns)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        param x: (B x c x d)\n",
        "        \"\"\"\n",
        "\n",
        "        xs = torch.split(x, self.width, dim=1)  # channel-wise split\n",
        "        ys = []\n",
        "\n",
        "        for i in range(self.scale):\n",
        "            if i == 0:\n",
        "                x_ = xs[i]\n",
        "                y_ = x_\n",
        "            elif i == 1:\n",
        "                x_ = xs[i]\n",
        "                y_ = self.bns[i - 1](self.convs[i - 1](x_))\n",
        "            else:\n",
        "                x_ = xs[i] + ys[i - 1]\n",
        "                y_ = self.bns[i - 1](self.convs[i - 1](x_))\n",
        "            ys.append(y_)\n",
        "\n",
        "        y = torch.cat(ys, dim=1)  # channel-wise concat\n",
        "        return y"
      ],
      "metadata": {
        "id": "bTWr-qOvlGG-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Res2_Conv1D_ReLU_BN(nn.Module):\n",
        "    def __init__(self, channel, scale, ks, stride, padding, dilation):\n",
        "        super(Res2_Conv1D_ReLU_BN, self).__init__()\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "            Res2_Conv1D(channel, scale, ks, stride, padding, dilation),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm1d(channel),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.network(x)\n",
        "        return y\n"
      ],
      "metadata": {
        "id": "QR4YThF7lLcr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SE_Block(nn.Module):\n",
        "    def __init__(self, c_in, c_mid):\n",
        "        super(SE_Block, self).__init__()\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(c_in, c_mid),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(c_mid, c_in),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        s = self.network(x.mean(dim=-1))\n",
        "        y = x * s.unsqueeze(-1)\n",
        "        return y"
      ],
      "metadata": {
        "id": "DHXw0R2KlNBO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SE_Res2_Block(nn.Module):\n",
        "    def __init__(self, channel, scale, ks, stride, padding, dilation):\n",
        "        super(SE_Res2_Block, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            Conv1D_ReLU_BN(channel, channel, 1, 1, 0, 1),\n",
        "            Res2_Conv1D_ReLU_BN(channel, scale, ks, stride, padding, dilation),\n",
        "            Conv1D_ReLU_BN(channel, channel, 1, 1, 0, 1),\n",
        "            SE_Block(channel, channel)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.network(x) + x\n",
        "        return y"
      ],
      "metadata": {
        "id": "8Xqb76GWlO2V"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentiveStatisticPool(nn.Module):\n",
        "    def __init__(self, c_in, c_mid):\n",
        "        super(AttentiveStatisticPool, self).__init__()\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv1d(c_in, c_mid, kernel_size=1),\n",
        "            nn.Tanh(),  # seems like most implementations uses tanh?\n",
        "            nn.Conv1d(c_mid, c_in, kernel_size=1),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x.shape: B x C x t\n",
        "        alpha = self.network(x)\n",
        "        mu_hat = torch.sum(alpha * x, dim=-1)\n",
        "        var = torch.sum(alpha * x ** 2, dim=-1) - mu_hat ** 2\n",
        "        std_hat = torch.sqrt(var.clamp(min=1e-9))\n",
        "        y = torch.cat([mu_hat, std_hat], dim=-1)\n",
        "        # y.shape: B x (c_in*2)\n",
        "        return y"
      ],
      "metadata": {
        "id": "iqEZzhUqlRD-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ECAPA_TDNN(nn.Module):\n",
        "    def __init__(self, c_in=80, c_mid=512, c_out=192):\n",
        "        super(ECAPA_TDNN, self).__init__()\n",
        "\n",
        "        self.layer1 = Conv1D_ReLU_BN(c_in, c_mid, 5, 1, 2, 1)\n",
        "        self.layer2 = SE_Res2_Block(c_mid, 8, 3, 1, 2, 2)\n",
        "        self.layer3 = SE_Res2_Block(c_mid, 8, 3, 1, 3, 3)\n",
        "        self.layer4 = SE_Res2_Block(c_mid, 8, 3, 1, 4, 4)\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "            # Figure 2 in https://arxiv.org/pdf/2005.07143.pdf seems like groupconv?\n",
        "            nn.Conv1d(c_mid * 3, 1536, kernel_size=1, groups=3),\n",
        "            AttentiveStatisticPool(1536, 128),\n",
        "        )\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(3072)\n",
        "        self.linear = nn.Linear(3072, c_out)\n",
        "        self.bn2 = nn.BatchNorm1d(c_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x.shape: B x C x t\n",
        "        y1 = self.layer1(x)\n",
        "        y2 = self.layer2(y1) + y1\n",
        "        y3 = self.layer3(y1 + y2) + y1 + y2\n",
        "        y4 = self.layer4(y1 + y2 + y3) + y1 + y2 + y3\n",
        "\n",
        "        y = torch.cat([y2, y3, y4], dim=1)  # channel-wise concat\n",
        "        y = self.network(y)\n",
        "\n",
        "        y = self.linear(self.bn1(y.unsqueeze(-1)).squeeze(-1))\n",
        "        y = self.bn2(y.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "        return y\n"
      ],
      "metadata": {
        "id": "NxADYVXplStH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input size: batch_size * seq_len * feat_dim\n",
        "x = torch.zeros(2, 80, 200)\n",
        "model = ECAPA_TDNN(80, 512, 192)\n",
        "out = model(x)\n",
        "print(model)\n",
        "print(out.shape)  # should be [2, 192]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TODvyXDblYaj",
        "outputId": "b62bd5e7-9621-4edb-dbd0-496850c4a231"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ECAPA_TDNN(\n",
            "  (layer1): Conv1D_ReLU_BN(\n",
            "    (network): Sequential(\n",
            "      (0): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): SE_Res2_Block(\n",
            "    (network): Sequential(\n",
            "      (0): Conv1D_ReLU_BN(\n",
            "        (network): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Res2_Conv1D_ReLU_BN(\n",
            "        (network): Sequential(\n",
            "          (0): Res2_Conv1D(\n",
            "            (convs): ModuleList(\n",
            "              (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
            "              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
            "              (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
            "              (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
            "              (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
            "              (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
            "              (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
            "            )\n",
            "            (bns): ModuleList(\n",
            "              (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (2): Conv1D_ReLU_BN(\n",
            "        (network): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (3): SE_Block(\n",
            "        (network): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layer3): SE_Res2_Block(\n",
            "    (network): Sequential(\n",
            "      (0): Conv1D_ReLU_BN(\n",
            "        (network): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Res2_Conv1D_ReLU_BN(\n",
            "        (network): Sequential(\n",
            "          (0): Res2_Conv1D(\n",
            "            (convs): ModuleList(\n",
            "              (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
            "              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
            "              (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
            "              (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
            "              (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
            "              (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
            "              (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
            "            )\n",
            "            (bns): ModuleList(\n",
            "              (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (2): Conv1D_ReLU_BN(\n",
            "        (network): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (3): SE_Block(\n",
            "        (network): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layer4): SE_Res2_Block(\n",
            "    (network): Sequential(\n",
            "      (0): Conv1D_ReLU_BN(\n",
            "        (network): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Res2_Conv1D_ReLU_BN(\n",
            "        (network): Sequential(\n",
            "          (0): Res2_Conv1D(\n",
            "            (convs): ModuleList(\n",
            "              (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
            "              (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
            "              (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
            "              (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
            "              (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
            "              (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
            "              (6): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
            "            )\n",
            "            (bns): ModuleList(\n",
            "              (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (2): Conv1D_ReLU_BN(\n",
            "        (network): Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (3): SE_Block(\n",
            "        (network): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (1): ReLU(inplace=True)\n",
            "          (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (3): Sigmoid()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (network): Sequential(\n",
            "    (0): Conv1d(1536, 1536, kernel_size=(1,), stride=(1,), groups=3)\n",
            "    (1): AttentiveStatisticPool(\n",
            "      (network): Sequential(\n",
            "        (0): Conv1d(1536, 128, kernel_size=(1,), stride=(1,))\n",
            "        (1): Tanh()\n",
            "        (2): Conv1d(128, 1536, kernel_size=(1,), stride=(1,))\n",
            "        (3): Softmax(dim=-1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (bn1): BatchNorm1d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (linear): Linear(in_features=3072, out_features=192, bias=True)\n",
            "  (bn2): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n",
            "torch.Size([2, 192])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analysis models"
      ],
      "metadata": {
        "id": "xtf5t203lab-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6UeZ7wNSiIol"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "#from models.ecapa import ECAPA_TDNN\n",
        "#from models.yin import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Linguistic(torch.nn.Module):\n",
        "    def __init__(self, conf=None):\n",
        "        print(\"INIT-L runs\")\n",
        "        \"\"\"we use the intermediate features of XLSR-53 for linguistic features. More specifically, we used\n",
        "        the output from the 12th layer of the 24-layer transformer encoder.\n",
        "        Args:\n",
        "            conf:\n",
        "        \"\"\"\n",
        "        super(Linguistic, self).__init__()\n",
        "        self.conf = conf\n",
        "\n",
        "        self.wav2vec2 = transformers.Wav2Vec2ForPreTraining.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\")\n",
        "        for param in self.wav2vec2.parameters():\n",
        "            param.requires_grad = False\n",
        "            param.grad = None\n",
        "        self.wav2vec2.eval()\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"FORWARD_L runs\")\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: torch.Tensor of shape (B x t)\n",
        "        Returns:\n",
        "            y: torch.Tensor of shape(B x C x t)\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            outputs = self.wav2vec2(x, output_hidden_states=True)\n",
        "        y = outputs.hidden_states[12]  \n",
        "        y = y.permute((0, 2, 1))  \n",
        "        return y\n",
        "\n",
        "    def train(self, mode: bool = True):\n",
        "        print(\"TRAIN-L runs\")\n",
        "        if not isinstance(mode, bool):\n",
        "            raise ValueError(\"training mode is expected to be boolean\")\n",
        "        self.training = mode\n",
        "        # for module in self.children():\n",
        "        #     module.train(mode)\n",
        "        return self"
      ],
      "metadata": {
        "id": "Gtw7FRHFmHok"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Speaker(torch.nn.Module):\n",
        "    def __init__(self, conf=None):\n",
        "        \"\"\"A speaker embedding network that uses the 1st layer of XLSR-53 as an input.\n",
        "        Args:\n",
        "            conf:\n",
        "        \"\"\"\n",
        "        super(Speaker, self).__init__()\n",
        "        self.conf = conf\n",
        "\n",
        "        self.wav2vec2 = transformers.Wav2Vec2ForPreTraining.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\")\n",
        "        for param in self.wav2vec2.parameters():\n",
        "            param.requires_grad = False\n",
        "            param.grad = None\n",
        "        self.wav2vec2.eval()\n",
        "\n",
        "        # c_in = 1024 for wav2vec2\n",
        "        # original paper[14] used 512 and 192 for c_mid and c_out, respectively\n",
        "        print(\"init runs\")\n",
        "        self.spk = ECAPA_TDNN(c_in=1024, c_mid=512, c_out=192)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: torch.Tensor of shape (B x t)\n",
        "        Returns:\n",
        "            y: torch.Tensor of shape (B x 192)\n",
        "        \"\"\"\n",
        "        print(\"Forward runs\")\n",
        "        with torch.no_grad():\n",
        "            outputs = self.wav2vec2(x, output_hidden_states=True)\n",
        "        y = outputs.hidden_states[1]  \n",
        "        y = y.permute((0, 2, 1))  \n",
        "        y = self.spk(y)  \n",
        "        y = torch.nn.functional.normalize(y, p=2, dim=-1)\n",
        "        return y\n",
        "\n",
        "    def train(self, mode: bool = True):\n",
        "        print(\"Train runs\")\n",
        "        if not isinstance(mode, bool):\n",
        "            raise ValueError(\"training mode is expected to be boolean\")\n",
        "        self.training = mode\n",
        "        # for module in self.children():\n",
        "        #     module.train(mode)\n",
        "        self.spk.train(mode)\n",
        "        return self"
      ],
      "metadata": {
        "id": "faWKpso-mPHA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Energy(torch.nn.Module):\n",
        "    def __init__(self, conf=None):\n",
        "        super(Energy, self).__init__()\n",
        "        self.conf = conf\n",
        "\n",
        "    def forward(self, mel):\n",
        "        \"\"\"For the energy feature, we simply took an average from a log-mel\n",
        "         spectrogram along the frequency axis.\n",
        "        Args:\n",
        "            mel: torch.Tensor of shape (B x t x C)\n",
        "        Returns:\n",
        "            y: torch.Tensor of shape (B x 1 x C)\n",
        "        \"\"\"\n",
        "        y = torch.mean(mel, dim=1, keepdim=True)  # B x 1(channel) x t\n",
        "        return y"
      ],
      "metadata": {
        "id": "xmHyLbNDmQ0W"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Pitch(torch.nn.Module):\n",
        "    def __init__(self, conf=None):\n",
        "        print(\"STARTED\")\n",
        "        super(Pitch, self).__init__()\n",
        "        self.conf = conf\n",
        "\n",
        "    @staticmethod\n",
        "    def midi_to_lag(m: int, sr: int, semitone_range: float = 12):\n",
        "        print(\"STARTED TWO\")\n",
        "        \"\"\"converts midi-to-lag, eq. (4)\n",
        "        Args:\n",
        "            m: midi\n",
        "            sr: sample_rate\n",
        "            semitone_range:\n",
        "        Returns:\n",
        "            lag: time lag(tau, c(m)) calculated from midi, eq. (4)\n",
        "        \"\"\"\n",
        "        f = 440 * math.pow(2, (m - 69) / semitone_range)\n",
        "        lag = sr / f\n",
        "        print(\"midi-to-lag done\")\n",
        "        return lag\n",
        "\n",
        "    @staticmethod\n",
        "    def yingram_from_cmndf(cmndfs: torch.Tensor, ms: list, sr: int = 22050) -> torch.Tensor:\n",
        "        \"\"\" yingram calculator from cMNDFs(cumulative Mean Normalized Difference Functions)\n",
        "        Args:\n",
        "            cmndfs: torch.Tensor\n",
        "                calculated cumulative mean normalized difference function\n",
        "            ms: list of midi(int)\n",
        "            sr: sampling rate\n",
        "        Returns:\n",
        "            y:\n",
        "                calculated batch yingram\n",
        "        \"\"\"\n",
        "        c_ms = np.asarray([Pitch.midi_to_lag(m, sr) for m in ms])\n",
        "        c_ms = torch.from_numpy(c_ms).to(cmndfs.device)\n",
        "        c_ms_ceil = torch.ceil(c_ms).long().to(cmndfs.device)\n",
        "        c_ms_floor = torch.floor(c_ms).long().to(cmndfs.device)\n",
        "\n",
        "        y = (cmndfs[:, c_ms_ceil] - cmndfs[:, c_ms_floor]) / (c_ms_ceil - c_ms_floor).unsqueeze(0) * (\n",
        "                c_ms - c_ms_floor).unsqueeze(0) + cmndfs[:, c_ms_floor]\n",
        "        print(\"yingram_from_cmndf done\")\n",
        "        return y\n",
        "\n",
        "    @staticmethod\n",
        "    def yingram(x: torch.Tensor, W: int = 2048, tau_max: int = 2048, sr: int = 22050, w_step: int = 256):\n",
        "        \"\"\"calculates yingram from raw audio (multi segment)\n",
        "        Args:\n",
        "            x: raw audio, torch.Tensor of shape (t)\n",
        "            W: yingram Window Size\n",
        "            tau_max:\n",
        "            sr: sampling rate\n",
        "            w_step: yingram bin step size\n",
        "        Returns:\n",
        "            yingram: yingram. torch.Tensor of shape (80 x t')\n",
        "        \"\"\"\n",
        "        # x.shape: t\n",
        "        w_len = W\n",
        "\n",
        "        startFrames = list(range(0, x.shape[-1] - w_len, w_step))\n",
        "        startFrames = np.asarray(startFrames)\n",
        "        # times = startFrames / sr\n",
        "        frames = [x[..., t:t + W] for t in startFrames]\n",
        "        frames_torch = torch.stack(frames, dim=0).to(x.device)\n",
        "\n",
        "        # If not using gpu, or torch not compatible, implemented numpy batch function is still fine\n",
        "        dfs = differenceFunctionTorch(frames_torch, frames_torch.shape[-1], tau_max)\n",
        "        cmndfs = cumulativeMeanNormalizedDifferenceFunctionTorch(dfs, tau_max)\n",
        "\n",
        "        midis = list(range(5, 85))\n",
        "        yingram = Pitch.yingram_from_cmndf(cmndfs, midis, sr)\n",
        "\n",
        "        print(\"yingram done\")\n",
        "        return yingram\n",
        "\n",
        "    @staticmethod\n",
        "    def yingram_batch(x: torch.Tensor, W: int = 2048, tau_max: int = 2048, sr: int = 22050, w_step: int = 256):\n",
        "        \"\"\"calculates yingram from batch raw audio.\n",
        "        currently calculates batch-wise through for loop, but seems it can be implemented to act batch-wise\n",
        "        Args:\n",
        "            x: torch.Tensor of shape (B x t)\n",
        "            W:\n",
        "            tau_max:\n",
        "            sr:\n",
        "            w_step:\n",
        "        Returns:\n",
        "            yingram: yingram. torch.Tensor of shape (B x 80 x t')\n",
        "        \"\"\"\n",
        "        batch_results = []\n",
        "        for i in range(len(x)):\n",
        "            yingram = Pitch.yingram(x[i], W, tau_max, sr, w_step)\n",
        "            batch_results.append(yingram)\n",
        "        result = torch.stack(batch_results, dim=0).float()\n",
        "        result = result.permute((0, 2, 1)).to(x.device)\n",
        "        print(\"yingram_batch done\")\n",
        "        return result"
      ],
      "metadata": {
        "id": "WlJUgS1ymcH2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Analysis(torch.nn.Module):\n",
        "    def __init__(self, conf=None):\n",
        "        \"\"\"joins all analysis modules into one\n",
        "        Args:\n",
        "            conf:\n",
        "        \"\"\"\n",
        "        super(Analysis, self).__init__()\n",
        "        self.conf = conf\n",
        "\n",
        "        self.linguistic = Linguistic()\n",
        "        self.speaker = Speaker()\n",
        "        self.energy = Energy()\n",
        "        self.pitch = Pitch()"
      ],
      "metadata": {
        "id": "MTb5qbibmeXu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "wav = torch.randn(2, 20000)\n",
        "mel = torch.randn(2, 80, 128)\n",
        "\n",
        "linguistic = Linguistic()\n",
        "speaker = Speaker()\n",
        "energy = Energy()\n",
        "pitch = Pitch()\n",
        "\n",
        "with torch.no_grad():\n",
        "    lps = linguistic(wav)\n",
        "    print(lps.shape)\n",
        "\n",
        "    s = speaker(wav)\n",
        "    print(s.shape)\n",
        "\n",
        "    e = energy(mel)\n",
        "    print(e.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226,
          "referenced_widgets": [
            "6225e794ccd747be8931ff4f3e529e96",
            "f9a6e958cb7d48b5bab0c424b9303cad",
            "c77b89834281495b981b7c1f84a21c9c",
            "570d12e320ea4cc09614b4559a729546",
            "b80450ed2e3b44d9bc4c2101b599c9d3",
            "de3a9c30675c485db1b17f4e13a0ff8c",
            "2c1fdc7e7ecf4b4eab9f7864c5360728",
            "08d06fb006724ca6a46d9d2c498b6e21",
            "a9e59e63391d48af9431218ad8c01d2e",
            "e1b55633b3b3439b995c71a4f0d81afb",
            "888fb87f83964bbdad45ca5c03eadd1a",
            "d68dd4095d684caf895d1b4e6c9c546f",
            "3a55b51510444565973a02dbfa4fbba5",
            "b0eb853c72c9413f9f3c2bffad7313a9",
            "09e101ce05ed4f058b5c5f268b9ee9e4",
            "250cfab4eaa54f13bb8626421da63106",
            "96675e35707f4b5092374250193971e2",
            "772d34fe149e460bbe938c244091589c",
            "574689e2ca1a4be8b07d4ccf46d44ecf",
            "02da289ab8d3450091fac60376e2b431",
            "653df1e0cab249468c10018829bb37b6",
            "4c8d9bab9e67473f946d95c219618011"
          ]
        },
        "id": "c9GpFWzOmgUI",
        "outputId": "d13a1593-db2a-47d1-8c35-345f918b3746"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INIT-L runs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.73k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6225e794ccd747be8931ff4f3e529e96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.18G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d68dd4095d684caf895d1b4e6c9c546f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init runs\n",
            "STARTED\n",
            "FORWARD_L runs\n",
            "torch.Size([2, 1024, 62])\n",
            "Forward runs\n",
            "torch.Size([2, 192])\n",
            "torch.Size([2, 1, 128])\n"
          ]
        }
      ]
    }
  ]
}